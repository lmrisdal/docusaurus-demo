"use strict";(self.webpackChunkdocusaurus_demo=self.webpackChunkdocusaurus_demo||[]).push([[6247],{3905:function(e,t,r){r.d(t,{Zo:function(){return c},kt:function(){return d}});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function o(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var l=n.createContext({}),u=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),m=u(r),d=a,h=m["".concat(l,".").concat(d)]||m[d]||p[d]||i;return r?n.createElement(h,s(s({ref:t},c),{},{components:r})):n.createElement(h,s({ref:t},c))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,s=new Array(i);s[0]=m;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:a,s[1]=o;for(var u=2;u<i;u++)s[u]=r[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},2656:function(e,t,r){r.r(t),r.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return o},metadata:function(){return u},toc:function(){return p}});var n=r(7462),a=r(3366),i=(r(7294),r(3905)),s=["components"],o={},l="Retry",u={unversionedId:"retry",id:"retry",title:"Retry",description:"- Retry",source:"@site/docs/retry.md",sourceDirName:".",slug:"/retry",permalink:"/retry",draft:!1,editUrl:"https://github.com/lmrisdal/docusaurus-demo/tree/main/docs/retry.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Resending",permalink:"/resending"}},c={},p=[{value:"Endpoint retry",id:"endpoint-retry",level:2},{value:"Engine retry",id:"engine-retry",level:2},{value:"Linear retry",id:"linear-retry",level:3},{value:"Backoff retry",id:"backoff-retry",level:3},{value:"Catastrophic failure retry",id:"catastrophic-failure-retry",level:2}],m={toc:p};function d(e){var t=e.components,r=(0,a.Z)(e,s);return(0,i.kt)("wrapper",(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"retry"},"Retry"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#retry"},"Retry"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#endpoint-retry"},"Endpoint retry")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#engine-retry"},"Engine retry"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#linear-retry"},"Linear retry")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#backoff-retry"},"Backoff retry")))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#catastrophic-failure-retry"},"Catastrophic failure retry"))))),(0,i.kt)("p",null,"CX uses multiple layers of retry to ensure the highest possible robustness. We currently use three types of retry:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Endpoint retry"),(0,i.kt)("li",{parentName:"ol"},"Engine retry"),(0,i.kt)("li",{parentName:"ol"},"Catastrophic failure retry")),(0,i.kt)("h2",{id:"endpoint-retry"},"Endpoint retry"),(0,i.kt)("p",null,"All adapters use retry logic to compensate for protocol instability on delivery and pickup of messages. Thus endpoint retry refers to the instant retry mechanisms used when the instability of the protocol or the receivers themselves are unreachable or experiencing some kind of transient failure. The nature of the retry varies by protocol and will be described in the specific articles per adapter, however all the adapters do have some similarities imposed by external limitations, such as the number of retries which varies by protocol but is kept within a time-range of 1 minute to conform to the transient nature of CX's scaling architecture.\\\nIn short endpoint retry is triggered instantly when a request fails, and has a number of retries that stagger inside an interval of 1 minute or less."),(0,i.kt)("h2",{id:"engine-retry"},"Engine retry"),(0,i.kt)("p",null,"Even though the adapters themselves retry instantly when a request fails prolonged failure will cause the message itself to fail after the grace period offered by the ",(0,i.kt)("a",{parentName:"p",href:"#endpoint-retry"},"endpoint retry"),". To handle these kind of failures CX has two different strategies for engine retry, both based on ",(0,i.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sequencing"},"Service Bus")," functionality. We call these strategies ",(0,i.kt)("em",{parentName:"p"},"linear")," and ",(0,i.kt)("em",{parentName:"p"},"backoff")," retry."),(0,i.kt)("h3",{id:"linear-retry"},"Linear retry"),(0,i.kt)("p",null,"Linear retry uses Service Bus' abandon message functionality to leverage internal retry mechanisms and retry the message a set number of times in a linear fashion. Every retry attempt also triggers the ",(0,i.kt)("a",{parentName:"p",href:"#endpoint-retry"},"endpoint retry"),", this means that the total number of retries are calculated thusly; (linear engine retry * endpoint retry) = total number of retries before failure.\\\nEvery engine uses an optimal number of retries based on the kind of operation attempted and the nature of the engine itself. That said, no engine retries more than 10 times or less than 3 while configured to use linear retry. See the individual engines documentation for specific information about what number and kind of retry is used for that engine."),(0,i.kt)("h3",{id:"backoff-retry"},"Backoff retry"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},(0,i.kt)("inlineCode",{parentName:"p"},"This functionality is in development. Read more on the:")," ",(0,i.kt)("a",{parentName:"p",href:"/Functionality"},"functionality page"),".")),(0,i.kt)("p",null,"Backoff retry uses the ",(0,i.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sequencing"},"message scheduling")," feature of Service Bus to stagger retries in a way that causes less load on external endpoints during peak traffic. In essence the backoff retry functionality keeps track of failures, and based upon customer configured or default variables, it delays traffic to more evenly distribute messages and external calls. The default variables are as follows (subject to change dependant on performance):"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Variable"),(0,i.kt)("th",{parentName:"tr",align:null},"Value"),(0,i.kt)("th",{parentName:"tr",align:null},"Description"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"MaxNumberOfRetries"),(0,i.kt)("td",{parentName:"tr",align:null},"5"),(0,i.kt)("td",{parentName:"tr",align:null},"The max number of retries or delay actions. When the maximum number of actions are reached the message is stopped and marked for potential manual retry. All actions count towards the max number. If a message is delayed 3 times and fails 2, the message will be stopped and marked.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"FailureCountIntervalMinutes"),(0,i.kt)("td",{parentName:"tr",align:null},"3"),(0,i.kt)("td",{parentName:"tr",align:null},"With each failure that causes the engine to terminate the message processing the ",(0,i.kt)("em",{parentName:"td"},"MaxErrorsPerInterval")," is incremented. This property control the reset time of ",(0,i.kt)("em",{parentName:"td"},"MaxErrorsPerInterval"),". This causes CX to count errors within the set interval and start delaying messages if ",(0,i.kt)("em",{parentName:"td"},"MaxErrorsPerInterval")," is hit within the interval set by this property. E.g. if this property is set to 3, the engine will count errors for 3 minutes and if ",(0,i.kt)("em",{parentName:"td"},"MaxErrorsPerInterval")," is set to 5 it will start delaying if we hit 5 error counts within those 3 minutes, if not we reset the count and do it all again.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"MaxErrorsPerInterval"),(0,i.kt)("td",{parentName:"tr",align:null},"1000"),(0,i.kt)("td",{parentName:"tr",align:null},"This is the max count of errors that can occur within the set ",(0,i.kt)("em",{parentName:"td"},"FailureCountIntervalMinutes"),". When the threshold set here is hit the engine will start to delay messages in hopes of reducing the load on the external service.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"ReQueueMaxDelayMinutes"),(0,i.kt)("td",{parentName:"tr",align:null},"6"),(0,i.kt)("td",{parentName:"tr",align:null},"When a message is delayed it is re-scheduled on the Service Bus within the interval of FailureCountIntervalMinutes and this property. Meaning that if this property is set to 6 minutes and FailureCountIntervalMinutes is set to 3 minutes, failed messages will be re-scheduled for processing 3-6 minutes from the time of scheduling. Messages are queued randomly within the interval until all slots are used then the process repeats if necessary.")))),(0,i.kt)("h2",{id:"catastrophic-failure-retry"},"Catastrophic failure retry"),(0,i.kt)("p",null,"When CX picks messages from a location or receives messages through its API, we do out outmost to ensure that the message is delivered and never lost within the CX engine. Catastrophic failure retry queues messages that experience connectivity loss to internal or external services or protocols on a Service Bus that is hosted in another data center. It is then reinserted into the original flow either automatically, or if the failure is persistent, manually after the fault is fixed."))}d.isMDXComponent=!0}}]);